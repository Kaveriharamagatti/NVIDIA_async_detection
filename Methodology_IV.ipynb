{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp/0SM5Q9ZowbfBz/fM5oM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaveriharamagatti/NVIDIA_async_detection/blob/main/Methodology_IV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD-sdj3CG9ck"
      },
      "outputs": [],
      "source": [
        "#CROPPING - EXTRACTING REGION OF INTEREST\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Read the image\n",
        "image = cv2.imread('/content/drive/MyDrive/cropping_model/2.png')\n",
        "\n",
        "# Get image dimensions\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Define the dimensions of the black box containing LEDs (assuming it's centered)\n",
        "# Assuming each LED has a diameter of 10 pixels\n",
        "led_diameter = 10\n",
        "led_spacing = 1  # Spacing between LEDs\n",
        "num_leds = 11  # Number of LEDs in each row and column\n",
        "\n",
        "black_box_width = num_leds * (led_diameter + led_spacing) - led_spacing\n",
        "black_box_height = num_leds * (led_diameter + led_spacing) - led_spacing\n",
        "\n",
        "# Calculate the original bounding box coordinates\n",
        "x1 = (width - black_box_width) // 2\n",
        "y1 = (height - black_box_height) // 2\n",
        "x2 = x1 + black_box_width\n",
        "y2 = y1 + black_box_height\n",
        "\n",
        "# Define individual margins for each side\n",
        "margin_left = 12\n",
        "margin_right = 12\n",
        "margin_up = 18\n",
        "margin_down = 12\n",
        "\n",
        "# Adjust the bounding box coordinates with the specified margins\n",
        "x1 = max(x1 - margin_left, 0)\n",
        "y1 = max(y1 - margin_up, 0)\n",
        "x2 = min(x2 + margin_right, width)\n",
        "y2 = min(y2 + margin_down, height)\n",
        "\n",
        "# Draw the increased bounding box on the image\n",
        "cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "# Specify the output folder path\n",
        "output_folder = '/content/drive/MyDrive/cropped_output'\n",
        "\n",
        "# Create the output folder if it does not exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Specify the output path including the filename and extension\n",
        "output_path = os.path.join(output_folder, 'output_image.png')\n",
        "\n",
        "# Store the image with the bounding box\n",
        "cv2.imwrite(output_path, image)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RETAINING REGION OF INTEREST\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('/content/drive/MyDrive/cropped_output/output_image.png')\n",
        "\n",
        "# Convert the image to HSV color space\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define lower and upper bounds for the green color\n",
        "lower_green = np.array([40, 40, 40])  # Lower bound for green color in HSV\n",
        "upper_green = np.array([70, 255, 255])  # Upper bound for green color in HSV\n",
        "\n",
        "# Threshold the HSV image to get only green colors\n",
        "mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Create a mask for the largest contour (assuming it's the green box)\n",
        "largest_contour = max(contours, key=cv2.contourArea)\n",
        "mask = np.zeros_like(mask)\n",
        "cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
        "\n",
        "# Bitwise AND mask and original image\n",
        "result = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "# Show the result\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Result with Mask Applied')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ltcnIM6JHLic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CROPPING REGION OF INTEREST\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('/content/drive/MyDrive/cropped_output/output_image.png')\n",
        "\n",
        "# Convert the image to HSV color space\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define lower and upper bounds for the green color\n",
        "lower_green = np.array([40, 40, 40])  # Lower bound for green color in HSV\n",
        "upper_green = np.array([70, 255, 255])  # Upper bound for green color in HSV\n",
        "\n",
        "# Threshold the HSV image to get only green colors\n",
        "mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Get the bounding box of the largest contour (assuming it's the green box)\n",
        "x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "\n",
        "# Crop the region inside the bounding box\n",
        "cropped_region = image[y:y+h, x:x+w]\n",
        "\n",
        "# Save the cropped region as an output image\n",
        "output_path = '/content/drive/MyDrive/cropped_output/cropped_region.png'\n",
        "cv2.imwrite(output_path, cropped_region)\n",
        "\n",
        "print(\"Cropped region saved successfully.\")\n",
        "\n",
        "# Show the cropped region\n",
        "plt.imshow(cv2.cvtColor(cropped_region, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Cropped Region')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9SYkorpZHT6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEMPLATE MATCHING AND CROPPING MATCHED REGION\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the main image\n",
        "main_image = cv2.imread('/content/drive/MyDrive/cropped_output/cropped_region.png')\n",
        "\n",
        "# Load the template image\n",
        "template = cv2.imread('/content/drive/MyDrive/cropped_data/4.png')\n",
        "\n",
        "# Check if the images are loaded successfully\n",
        "if main_image is None or template is None:\n",
        "    print(\"Error: Could not load the images.\")\n",
        "    exit()\n",
        "\n",
        "# Convert both images to grayscale\n",
        "main_gray = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
        "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Perform template matching\n",
        "result = cv2.matchTemplate(main_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
        "\n",
        "# Define a threshold to consider a match\n",
        "threshold = 0.8\n",
        "\n",
        "# Find locations where the result is above the threshold\n",
        "locations = np.where(result >= threshold)\n",
        "\n",
        "# If there are no matches, print \"False\" and exit\n",
        "if len(locations[0]) == 0:\n",
        "    print(\"False\")\n",
        "    exit()\n",
        "\n",
        "# Loop over all the locations and mark the matches\n",
        "for loc in zip(*locations[::-1]):\n",
        "    cv2.rectangle(main_image, loc, (loc[0] + template.shape[1], loc[1] + template.shape[0]), (0, 255, 0), 2)\n",
        "\n",
        "# Show the result using matplotlib\n",
        "plt.imshow(cv2.cvtColor(main_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Template Matching Result')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Extract the first matched region\n",
        "top_left = (locations[1][0], locations[0][0])\n",
        "bottom_right = (top_left[0] + template.shape[1], top_left[1] + template.shape[0])\n",
        "matched_region = main_image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
        "\n",
        "# Resize the matched region to the specified dimensions (706x463)\n",
        "output_width, output_height = 706, 463\n",
        "resized_matched_region = cv2.resize(matched_region, (output_width, output_height))\n",
        "\n",
        "# Save the resized matched region to a file\n",
        "cv2.imwrite('/content/drive/MyDrive/cropped_output/matched_region.png', resized_matched_region)\n",
        "\n",
        "# Print \"True\"\n",
        "print(\"True\")\n",
        "\n",
        "# Display the resized cropped image\n",
        "plt.imshow(cv2.cvtColor(resized_matched_region, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Matched Region')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lrNdJsuJHkve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RESIZING\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "# Function to resize images in a directory\n",
        "def resize_images(input_folder, output_folder, desired_width, desired_height):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # List all files in the input folder\n",
        "    image_files = os.listdir(input_folder)\n",
        "\n",
        "    # Resize each image and save it in the output folder\n",
        "    for file_name in image_files:\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, file_name)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Resize the image\n",
        "        resized_image = cv2.resize(image, (desired_width, desired_height))\n",
        "\n",
        "        # Save the resized image to the output folder\n",
        "        output_path = os.path.join(output_folder, file_name)\n",
        "        cv2.imwrite(output_path, resized_image)\n",
        "\n",
        "        # Display the resized image\n",
        "        cv2_imshow(resized_image)\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Amit_sir2'\n",
        "output_folder = '/content/drive/MyDrive/cropped_ouput'\n",
        "\n",
        "# Define the desired width and height\n",
        "desired_width = 200\n",
        "desired_height = 180\n",
        "\n",
        "# Resize images in the input folder and save them in the output folder\n",
        "resize_images(input_folder, output_folder, desired_width, desired_height)\n"
      ],
      "metadata": {
        "id": "LmKhFR94Hs2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RETAINING WHITE AND RED REGIONS\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "# Function to process each image\n",
        "def process_image(image_path, output_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert the image to the HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define the range of bright red color in HSV\n",
        "    lower_bright_red1 = np.array([0, 150, 150])\n",
        "    upper_bright_red1 = np.array([10, 255, 255])\n",
        "    lower_bright_red2 = np.array([170, 150, 150])\n",
        "    upper_bright_red2 = np.array([180, 255, 255])\n",
        "\n",
        "    # Define the range of white color in HSV\n",
        "    lower_white = np.array([0, 0, 200])\n",
        "    upper_white = np.array([180, 25, 255])\n",
        "\n",
        "    # Create masks for the bright red and white LEDs\n",
        "    mask_bright_red1 = cv2.inRange(hsv_image, lower_bright_red1, upper_bright_red1)\n",
        "    mask_bright_red2 = cv2.inRange(hsv_image, lower_bright_red2, upper_bright_red2)\n",
        "    mask_bright_red = cv2.bitwise_or(mask_bright_red1, mask_bright_red2)\n",
        "    mask_white = cv2.inRange(hsv_image, lower_white, upper_white)\n",
        "    mask_leds = cv2.bitwise_or(mask_bright_red, mask_white)\n",
        "\n",
        "    # Invert the mask to get the background\n",
        "    mask_background = cv2.bitwise_not(mask_leds)\n",
        "\n",
        "    # Darken the background by reducing its brightness\n",
        "    background = cv2.bitwise_and(image, image, mask=mask_background)\n",
        "    background = cv2.addWeighted(background, 0.5, np.zeros_like(background), 0.5, 0)\n",
        "\n",
        "    # Combine the darkened background with the original LEDs\n",
        "    result_image = cv2.bitwise_or(background, cv2.bitwise_and(image, image, mask=mask_leds))\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result_image)\n",
        "\n",
        "    # Return the result for display\n",
        "    return result_image\n",
        "\n",
        "# Paths to input images\n",
        "image_paths = [\n",
        "    '/content/drive/MyDrive/cropped_ouput/1.png',\n",
        "    '/content/drive/MyDrive/cropped_ouput/2.png'\n",
        "]\n",
        "\n",
        "# Output directory\n",
        "output_directory = '/content/drive/MyDrive/pre_preocessed'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Process and display each image\n",
        "results = []\n",
        "for i, image_path in enumerate(image_paths):\n",
        "    output_path = os.path.join(output_directory, f'Image{i+1}_Bright_Red_and_White_LEDs_Enhanced.jpg')\n",
        "    result = process_image(image_path, output_path)\n",
        "    results.append(result)\n",
        "\n",
        "# Display the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, result_image in enumerate(results):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Image {i+1}: Bright Red and White LEDs Enhanced')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UXQGBiI0IKJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REMOVING BACKGROUND\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "def segment_image(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert the image to the HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define the range of bright red color in HSV\n",
        "    lower_bright_red1 = np.array([0, 150, 150])\n",
        "    upper_bright_red1 = np.array([10, 255, 255])\n",
        "    lower_bright_red2 = np.array([170, 150, 150])\n",
        "    upper_bright_red2 = np.array([180, 255, 255])\n",
        "\n",
        "    # Define the range of white color in HSV\n",
        "    lower_white = np.array([0, 0, 220])\n",
        "    upper_white = np.array([180, 25, 255])\n",
        "\n",
        "    # Create masks for the bright red and white LEDs\n",
        "    mask_bright_red1 = cv2.inRange(hsv_image, lower_bright_red1, upper_bright_red1)\n",
        "    mask_bright_red2 = cv2.inRange(hsv_image, lower_bright_red2, upper_bright_red2)\n",
        "    mask_bright_red = cv2.bitwise_or(mask_bright_red1, mask_bright_red2)\n",
        "    mask_white = cv2.inRange(hsv_image, lower_white, upper_white)\n",
        "    mask_leds = cv2.bitwise_or(mask_bright_red, mask_white)\n",
        "\n",
        "    # Create a mask to retain only the segmented part\n",
        "    mask = mask_leds\n",
        "\n",
        "    # Apply the mask to the original image to extract the segmented part\n",
        "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    return segmented_image\n",
        "\n",
        "def main():\n",
        "    # Path to the input images\n",
        "    image_path = '/content/drive/MyDrive/pre_preocessed/Image1_Bright_Red_and_White_LEDs_Enhanced.jpg'\n",
        "    image_path1 = '/content/drive/MyDrive/pre_preocessed/Image2_Bright_Red_and_White_LEDs_Enhanced.jpg'\n",
        "\n",
        "    # Perform image segmentation\n",
        "    segmented_image = segment_image(image_path)\n",
        "    segmented_image1 = segment_image(image_path1)\n",
        "\n",
        "    # Display the segmented images\n",
        "    cv2_imshow(segmented_image)\n",
        "    cv2_imshow(segmented_image1)\n",
        "\n",
        "    # Create a folder to save the segmented images\n",
        "    output_folder = '/content/drive/MyDrive/output_nvidia1'\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save the segmented images\n",
        "    cv2.imwrite(os.path.join(output_folder, 'segmented_image1.jpg'), segmented_image)\n",
        "    cv2.imwrite(os.path.join(output_folder, 'segmented_image2.jpg'), segmented_image1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "C4u9vKOUISJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EDGE MAPPING\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function to apply edge detection and save the result\n",
        "def apply_edge_detection(image_path, output_folder):\n",
        "    # Read the image\n",
        "    original_image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if the image was loaded successfully\n",
        "    if original_image is None:\n",
        "        print(f\"Error: Unable to read image at path: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Convert the original image to grayscale\n",
        "    gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform Canny edge detection to detect edges\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "    # Retain the original color and intensity of the image after edge detection\n",
        "    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "    result = cv2.addWeighted(original_image, 1, edges_rgb, 1, 0)\n",
        "\n",
        "    # Save the result\n",
        "    filename = os.path.basename(image_path)\n",
        "    output_path = os.path.join(output_folder, f'edges_{filename}')\n",
        "    cv2.imwrite(output_path, result)\n",
        "    print(f\"Edge-detected image saved to: {output_path}\")\n",
        "\n",
        "    # Display the original and edge-detected images\n",
        "    cv2_imshow(original_image)\n",
        "    cv2_imshow(result)\n",
        "\n",
        "# Input image paths\n",
        "image_paths = [\n",
        "    '/content/drive/MyDrive/output_nvidia1/segmented_image1.jpg',\n",
        "    '/content/drive/MyDrive/output_nvidia1/segmented_image2.jpg'\n",
        "]\n",
        "\n",
        "# Output folder\n",
        "output_folder = '/content/drive/MyDrive/output_nvidia'\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Process each image\n",
        "for image_path in image_paths:\n",
        "    apply_edge_detection(image_path, output_folder)\n"
      ],
      "metadata": {
        "id": "5zT50EnaIdG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ASYNC DETECTION\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def detect_blobs(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Set up the blob detector parameters\n",
        "    params = cv2.SimpleBlobDetector_Params()\n",
        "\n",
        "    # Change thresholds\n",
        "    params.minThreshold = 10\n",
        "    params.maxThreshold = 200\n",
        "\n",
        "    # Filter by Area.\n",
        "    params.filterByArea = True\n",
        "    params.minArea = 150\n",
        "\n",
        "    # Filter by Circularity\n",
        "    params.filterByCircularity = True\n",
        "    params.minCircularity = 0.1\n",
        "\n",
        "    # Filter by Convexity\n",
        "    params.filterByConvexity = True\n",
        "    params.minConvexity = 0.87\n",
        "\n",
        "    # Filter by Inertia\n",
        "    params.filterByInertia = True\n",
        "    params.minInertiaRatio = 0.01\n",
        "\n",
        "    # Create a blob detector with the parameters\n",
        "    detector = cv2.SimpleBlobDetector_create(params)\n",
        "\n",
        "    # Detect blobs\n",
        "    keypoints = detector.detect(gray_image)\n",
        "\n",
        "    return keypoints\n",
        "\n",
        "def compare_images(image1, image2):\n",
        "    # Detect blobs in both images\n",
        "    keypoints1 = detect_blobs(image1)\n",
        "    keypoints2 = detect_blobs(image2)\n",
        "\n",
        "    # Count the number of blobs in each image\n",
        "    count1 = len(keypoints1)\n",
        "    count2 = len(keypoints2)\n",
        "\n",
        "    if count1 != count2:\n",
        "        result_text = \"Async: Different count of glowing LEDs\"\n",
        "    else:\n",
        "        # Check if positions are the same\n",
        "        same_positions = True\n",
        "        for kp1, kp2 in zip(keypoints1, keypoints2):\n",
        "            if abs(kp1.pt[0] - kp2.pt[0]) > 5 or abs(kp1.pt[1] - kp2.pt[1]) > 5:\n",
        "                same_positions = False\n",
        "                break\n",
        "\n",
        "        if same_positions:\n",
        "            result_text = \"Sync: Same count and positions of glowing LEDs\"\n",
        "        else:\n",
        "            result_text = \"Async: Same count but different positions of glowing LEDs\"\n",
        "\n",
        "    # Draw detected blobs on the images\n",
        "    im_with_keypoints1 = cv2.drawKeypoints(image1, keypoints1, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    im_with_keypoints2 = cv2.drawKeypoints(image2, keypoints2, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "    # Display the images with detected blobs\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(im_with_keypoints1, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Image 1: Detected Blobs')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(im_with_keypoints2, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Image 2: Detected Blobs')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(result_text)\n",
        "    plt.show()\n",
        "\n",
        "# Load images\n",
        "image1 = cv2.imread('/content/drive/MyDrive/output_nvidia/edges_segmented_image1.jpg')\n",
        "image2 = cv2.imread('/content/drive/MyDrive/output_nvidia/edges_segmented_image2.jpg')\n",
        "\n",
        "# Compare images\n",
        "compare_images(image1, image2)\n"
      ],
      "metadata": {
        "id": "dF79eIBFIinZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}